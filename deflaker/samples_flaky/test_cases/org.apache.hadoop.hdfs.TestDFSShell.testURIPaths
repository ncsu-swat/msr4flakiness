public void testURIPaths() throws Exception {
    Configuration srcConf = new HdfsConfiguration();
    Configuration dstConf = new HdfsConfiguration();
    MiniDFSCluster srcCluster = null;
    MiniDFSCluster dstCluster = null;
    String bak = System.getProperty("test.build.data");
    try {
        srcCluster = new MiniDFSCluster.Builder(srcConf).numDataNodes(2).build();
        File nameDir = new File(new File(bak), "dfs_tmp_uri/");
        nameDir.mkdirs();
        System.setProperty("test.build.data", nameDir.toString());
        dstCluster = new MiniDFSCluster.Builder(dstConf).numDataNodes(2).build();
        FileSystem srcFs = srcCluster.getFileSystem();
        FileSystem dstFs = dstCluster.getFileSystem();
        FsShell shell = new FsShell();
        shell.setConf(srcConf);
        // check for ls
        String[] argv = new String[2];
        argv[0] = "-ls";
        argv[1] = dstFs.getUri().toString() + "/";
        int ret = ToolRunner.run(shell, argv);
        assertEquals("ls works on remote uri ", 0, ret);
        // check for rm -r
        dstFs.mkdirs(new Path("/hadoopdir"));
        argv = new String[2];
        argv[0] = "-rmr";
        argv[1] = dstFs.getUri().toString() + "/hadoopdir";
        ret = ToolRunner.run(shell, argv);
        assertEquals("-rmr works on remote uri " + argv[1], 0, ret);
        // check du
        argv[0] = "-du";
        argv[1] = dstFs.getUri().toString() + "/";
        ret = ToolRunner.run(shell, argv);
        assertEquals("du works on remote uri ", 0, ret);
        // check put
        File furi = new File(TEST_ROOT_DIR, "furi");
        createLocalFile(furi);
        argv = new String[3];
        argv[0] = "-put";
        argv[1] = furi.toString();
        argv[2] = dstFs.getUri().toString() + "/furi";
        ret = ToolRunner.run(shell, argv);
        assertEquals(" put is working ", 0, ret);
        // check cp
        argv[0] = "-cp";
        argv[1] = dstFs.getUri().toString() + "/furi";
        argv[2] = srcFs.getUri().toString() + "/furi";
        ret = ToolRunner.run(shell, argv);
        assertEquals(" cp is working ", 0, ret);
        assertTrue(srcFs.exists(new Path("/furi")));
        // check cat
        argv = new String[2];
        argv[0] = "-cat";
        argv[1] = dstFs.getUri().toString() + "/furi";
        ret = ToolRunner.run(shell, argv);
        assertEquals(" cat is working ", 0, ret);
        // check chown
        dstFs.delete(new Path("/furi"), true);
        dstFs.delete(new Path("/hadoopdir"), true);
        String file = "/tmp/chownTest";
        Path path = new Path(file);
        Path parent = new Path("/tmp");
        Path root = new Path("/");
        TestDFSShell.writeFile(dstFs, path);
        runCmd(shell, "-chgrp", "-R", "herbivores", dstFs.getUri().toString() + "/*");
        confirmOwner(null, "herbivores", dstFs, parent, path);
        runCmd(shell, "-chown", "-R", ":reptiles", dstFs.getUri().toString() + "/");
        confirmOwner(null, "reptiles", dstFs, root, parent, path);
        // check if default hdfs:/// works
        argv[0] = "-cat";
        argv[1] = "hdfs:///furi";
        ret = ToolRunner.run(shell, argv);
        assertEquals(" default works for cat", 0, ret);
        argv[0] = "-ls";
        argv[1] = "hdfs:///";
        ret = ToolRunner.run(shell, argv);
        assertEquals("default works for ls ", 0, ret);
        argv[0] = "-rmr";
        argv[1] = "hdfs:///furi";
        ret = ToolRunner.run(shell, argv);
        assertEquals("default works for rm/rmr", 0, ret);
    } finally {
        System.setProperty("test.build.data", bak);
        if (null != srcCluster) {
            srcCluster.shutdown();
        }
        if (null != dstCluster) {
            dstCluster.shutdown();
        }
    }
}
