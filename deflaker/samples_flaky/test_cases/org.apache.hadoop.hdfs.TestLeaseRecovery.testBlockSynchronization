/**
 * The following test first creates a file with a few blocks.
 * It randomly truncates the replica of the last block stored in each datanode.
 * Finally, it triggers block synchronization to synchronize all stored block.
 */
public void testBlockSynchronization() throws Exception {
    final int ORG_FILE_SIZE = 3000;
    Configuration conf = new HdfsConfiguration();
    conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, BLOCK_SIZE);
    conf.setBoolean("dfs.support.append", true);
    MiniDFSCluster cluster = null;
    try {
        cluster = new MiniDFSCluster.Builder(conf).numDataNodes(5).build();
        cluster.waitActive();
        // create a file
        DistributedFileSystem dfs = (DistributedFileSystem) cluster.getFileSystem();
        String filestr = "/foo";
        Path filepath = new Path(filestr);
        DFSTestUtil.createFile(dfs, filepath, ORG_FILE_SIZE, REPLICATION_NUM, 0L);
        assertTrue(dfs.exists(filepath));
        DFSTestUtil.waitReplication(dfs, filepath, REPLICATION_NUM);
        // get block info for the last block
        LocatedBlock locatedblock = TestInterDatanodeProtocol.getLastLocatedBlock(dfs.dfs.getNamenode(), filestr);
        DatanodeInfo[] datanodeinfos = locatedblock.getLocations();
        assertEquals(REPLICATION_NUM, datanodeinfos.length);
        // connect to data nodes
        DataNode[] datanodes = new DataNode[REPLICATION_NUM];
        for (int i = 0; i < REPLICATION_NUM; i++) {
            datanodes[i] = cluster.getDataNode(datanodeinfos[i].getIpcPort());
            assertTrue(datanodes[i] != null);
        }
        // verify Block Info
        ExtendedBlock lastblock = locatedblock.getBlock();
        DataNode.LOG.info("newblocks=" + lastblock);
        for (int i = 0; i < REPLICATION_NUM; i++) {
            checkMetaInfo(lastblock, datanodes[i]);
        }
        DataNode.LOG.info("dfs.dfs.clientName=" + dfs.dfs.clientName);
        cluster.getNameNodeRpc().append(filestr, dfs.dfs.clientName);
        // expire lease to trigger block recovery.
        waitLeaseRecovery(cluster);
        Block[] updatedmetainfo = new Block[REPLICATION_NUM];
        long oldSize = lastblock.getNumBytes();
        lastblock = TestInterDatanodeProtocol.getLastLocatedBlock(dfs.dfs.getNamenode(), filestr).getBlock();
        long currentGS = lastblock.getGenerationStamp();
        for (int i = 0; i < REPLICATION_NUM; i++) {
            updatedmetainfo[i] = datanodes[i].data.getStoredBlock(lastblock.getBlockPoolId(), lastblock.getBlockId());
            assertEquals(lastblock.getBlockId(), updatedmetainfo[i].getBlockId());
            assertEquals(oldSize, updatedmetainfo[i].getNumBytes());
            assertEquals(currentGS, updatedmetainfo[i].getGenerationStamp());
        }
        // verify that lease recovery does not occur when namenode is in safemode
        System.out.println("Testing that lease recovery cannot happen during safemode.");
        filestr = "/foo.safemode";
        filepath = new Path(filestr);
        dfs.create(filepath, (short) 1);
        cluster.getNameNodeRpc().setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_ENTER);
        assertTrue(dfs.dfs.exists(filestr));
        DFSTestUtil.waitReplication(dfs, filepath, (short) 1);
        waitLeaseRecovery(cluster);
        // verify that we still cannot recover the lease
        LeaseManager lm = NameNodeAdapter.getLeaseManager(cluster.getNamesystem());
        assertTrue("Found " + lm.countLease() + " lease, expected 1", lm.countLease() == 1);
        cluster.getNameNodeRpc().setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_LEAVE);
    } finally {
        if (cluster != null) {
            cluster.shutdown();
        }
    }
}
